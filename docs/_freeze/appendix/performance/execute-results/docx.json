{
  "hash": "ddac92142873b6c99b543cba354cc8e1",
  "result": {
    "engine": "julia",
    "markdown": "---\ntitle: \"Performance tricks\"\ncode-fold: show\n---\n\n## Hurwitz Check\n\nCreate our nice model.\nAssume to have run the `poles` function and that you have a vector of eigenvalues. For simplicity I will create an arbitrary vector with the first 100 values in $-1$ and the last 100 values as random around $0$.\n\n::: {.cell execution_count=1}\n``` {.julia .cell-code}\nusing BenchmarkTools\n\nvbig = [zeros(ComplexF64,100).-1 ; rand(ComplexF64,100).-0.5];\n\nvbig[[1,end]]\n```\n\n::: {.cell-output .cell-output-display execution_count=1}\n```\n2-element Vector{ComplexF64}:\n                  -1.0 + 0.0im\n -0.030437584033531584 + 0.17283801604223903im\n```\n:::\n:::\n\n\n\n### `for` loop\n\n\nWith a naive approach we check if all the  elements are in the LHP: make a function that iterates and returns false if it hits a pole with positive real part.\n\n\n::: {.cell execution_count=1}\n``` {.julia .cell-code}\nfunction isHurwitz(v)\n    for i in eachindex(v)\n        if real(v[i])>0.0\n            return false\n        end\n    end\n    return true\nend\n\n@benchmark isHurwitz($(Ref(vbig))[])\n```\n\n::: {.cell-output .cell-output-display execution_count=1}\n```\nBenchmarkTools.Trial: 10000 samples with 987 evaluations per sample.\n Range (min … max):  49.949 ns … 969.301 ns  ┊ GC (min … max): 0.00% … 0.00%\n Time  (median):     54.306 ns               ┊ GC (median):    0.00%\n Time  (mean ± σ):   57.041 ns ±  22.237 ns  ┊ GC (mean ± σ):  0.00% ± 0.00%\n\n  ▆▇▆█▇▅▄▃▂▂▁▁▁▁                                               ▂\n  ██████████████▇█▇▇▆▆▆▆▇▆▆▅▅▅▆▅▆▄▄▅▄▅▅▅▅▅▅▄▄▅▄▁▅▃▃▄▄▆▇▁▁▅▆▇▆▆ █\n  49.9 ns       Histogram: log(frequency) by time       126 ns <\n\n Memory estimate: 0 bytes, allocs estimate: 0.\n```\n:::\n:::\n\n\n\nWe have our baseline. We can probably squeeze out some more performance but I'm still a Julia noob.\n\n\n### `all()`\n\n\nLet's try using some of the built-in declarative functions:\n\n::: {.cell execution_count=1}\n``` {.julia .cell-code}\n@benchmark all(real($vbig).<=0.0)\n```\n\n::: {.cell-output .cell-output-display execution_count=1}\n```\nBenchmarkTools.Trial: 10000 samples with 746 evaluations per sample.\n Range (min … max):  183.378 ns …  22.068 μs  ┊ GC (min … max):  0.00% … 97.78%\n Time  (median):     261.662 ns               ┊ GC (median):     0.00%\n Time  (mean ± σ):   445.850 ns ± 864.436 ns  ┊ GC (mean ± σ):  32.85% ± 16.78%\n\n  █▇▅▃▁▁▁▁                                                      ▂\n  ██████████▇▆▅▅▅▄▄▅▃▃▁▁▁▁▁▃▅▆▅▅▃▃▃▄▃▃▄▄▃▄▅▆▇▇▇▇▇▆▅▆▅▆▅▅▅▅▅▅▅▅▆ █\n  183 ns        Histogram: log(frequency) by time        5.1 μs <\n\n Memory estimate: 1.75 KiB, allocs estimate: 5.\n```\n:::\n:::\n\n\n\nSimple `all()`, when given a tuple it checks if all the values are `True`, otherwise it stops when it encounters the first `False`. \n\nWe can see that it's a tad slower. This is because it's creating a new vector with just the real parts, then it's creating a new vector with only the boolean results and then it's checking if there are any False results. \n\nThis results in a lot of allocations and wasted resources.\n\n\n::: {.cell execution_count=1}\n``` {.julia .cell-code}\n@benchmark all(<=(0.0),real($vbig))\n```\n\n::: {.cell-output .cell-output-display execution_count=1}\n```\nBenchmarkTools.Trial: 10000 samples with 759 evaluations per sample.\n Range (min … max):  144.664 ns …  31.398 μs  ┊ GC (min … max):  0.00% … 97.98%\n Time  (median):     226.746 ns               ┊ GC (median):     0.00%\n Time  (mean ± σ):   344.335 ns ± 699.060 ns  ┊ GC (mean ± σ):  22.41% ± 15.26%\n\n  ▂██▆▃▂▁       ▁▂▁▁▁                                           ▂\n  ████████▇▇▆▅▇███████▇▇▇▆▅▅▃▄▄▄▁▄▃▃▃▁▁▄▃▃▃▁▁▁▁▁▁▁▁▃▄▆▆▇███▇▆▇▆ █\n  145 ns        Histogram: log(frequency) by time       2.44 μs <\n\n Memory estimate: 1.62 KiB, allocs estimate: 2.\n```\n:::\n:::\n\n\n\n\nA smarter way is to skip on of the allocations by creating the vector of real parts and then checking row by row if the non-positivity check fails.\n\n\n::: {.cell execution_count=1}\n``` {.julia .cell-code}\n@benchmark all(i -> real(i)<=0.0,$vbig)\n```\n\n::: {.cell-output .cell-output-display execution_count=1}\n```\nBenchmarkTools.Trial: 10000 samples with 987 evaluations per sample.\n Range (min … max):  49.139 ns …  2.022 μs  ┊ GC (min … max): 0.00% … 0.00%\n Time  (median):     51.773 ns              ┊ GC (median):    0.00%\n Time  (mean ± σ):   53.295 ns ± 22.061 ns  ┊ GC (mean ± σ):  0.00% ± 0.00%\n\n  ▅▆█▃▂▂                                                      ▁\n  ███████▇▅▆▆▅▄▅▃▄▄▁▅▅▅▄▃▄▅▄▄▄▁▃▃▃▅▁▄▃▄▃▃▃▄▁▄▃▃▃▃▃▁▃▃▃▃▃▄▄▃▁█ █\n  49.1 ns      Histogram: log(frequency) by time       116 ns <\n\n Memory estimate: 0 bytes, allocs estimate: 0.\n```\n:::\n:::\n\n\nWe can do better: Instead of converting into real the full vector it checks element by element if it's in the LHP. It returns false at the first failure. We finally have a comparable result to the benchmark function but in a more compact way. \n\nIs it cleaner? That's subjective.\n\n### `mapreduce()`\n\nFinally we try the MapReduce approach. This allows a better utilization of your processor without the necessity of learning parallel programming.\n\n::: {.cell execution_count=1}\n``` {.julia .cell-code}\n@benchmark mapreduce(i->real(i)<=0.0, &, $vbig)\n```\n\n::: {.cell-output .cell-output-display execution_count=1}\n```\nBenchmarkTools.Trial: 10000 samples with 993 evaluations per sample.\n Range (min … max):  42.095 ns … 692.346 ns  ┊ GC (min … max): 0.00% … 0.00%\n Time  (median):     43.807 ns               ┊ GC (median):    0.00%\n Time  (mean ± σ):   46.318 ns ±  15.245 ns  ┊ GC (mean ± σ):  0.00% ± 0.00%\n\n  ▇█▆▄▅▄▂▁ ▁  ▁                                                ▂\n  █████████████▆▆▆▆▅▇▆█▆▆▅▄▅▄▄▃▆▆▃▁▄▅▅▁▃▄▃▁▄▄▄▃▄▄▅▆▃▄▃▄▄▅▇▆▇▆▆ █\n  42.1 ns       Histogram: log(frequency) by time       102 ns <\n\n Memory estimate: 0 bytes, allocs estimate: 0.\n```\n:::\n:::\n\n\n\nWe squeeze the last bit of performance and beat the initial benchmark, not by much but still appreciable.\n\n",
    "supporting": [
      "performance_files\\figure-docx"
    ],
    "filters": []
  }
}